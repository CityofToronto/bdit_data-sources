{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b81dce7-5261-414d-bab3-de188ac69eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import requests\n",
    "import datetime\n",
    "from psycopg2 import connect\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extras import execute_values\n",
    "import logging\n",
    "import re\n",
    "from time import sleep\n",
    "import click\n",
    "CONFIG = configparser.ConfigParser()\n",
    "CONFIG.read('/home/bqu/db_ec2.cfg')\n",
    "#CONFIG.read('/home/bqu/db_morbius.cfg')\n",
    "dbset = CONFIG['DBSETTINGS']\n",
    "con = connect(**dbset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df7af6-ebdb-4fbc-8de1-fa0806b3756a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae07788e-24fd-4aa4-9c36-c90c627c7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The following provides information about the code when it is running and prints out the log messages \n",
    "if they are of logging level equal to or greater than INFO\"\"\"\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede82259-0284-438f-9a0c-12b479d2198a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get mapserver name and generate table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4905567-4aac-4bd8-aa73-138a485bc2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mapserver_name(mapserver_n):\n",
    "    \"\"\"\n",
    "    Function to return the mapserver name from integer.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    mapserver_n : numeric\n",
    "        The number of mapserver we will be accessing. 0 for 'cot_geospatial'\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    name : string\n",
    "        The name of the mapserver\n",
    "    \"\"\"\n",
    "    \n",
    "    switcher ={\n",
    "        0 : 'cot_geospatial',\n",
    "        2 : 'cot_geospatial2',\n",
    "        3 : 'cot_geospatial3',\n",
    "        5 : 'cot_geospatial5',\n",
    "        6 : 'cot_geospatial6',\n",
    "        7 : 'cot_geospatial7',\n",
    "        8 : 'cot_geospatial8',\n",
    "        10 : 'cot_geospatial10',\n",
    "        11 : 'cot_geospatial11',\n",
    "        12 : 'cot_geospatial12',\n",
    "        13 : 'cot_geospatial13',\n",
    "        14 : 'cot_geospatial14',\n",
    "        15 : 'cot_geospatial15',\n",
    "        16 : 'cot_geospatial16',\n",
    "        17 : 'cot_geospatial17',\n",
    "        18 : 'cot_geospatial18',\n",
    "        19 : 'cot_geospatial19',\n",
    "        20 : 'cot_geospatial20',\n",
    "        21 : 'cot_geospatial21',\n",
    "        22 : 'cot_geospatial22',\n",
    "        23 : 'cot_geospatial23',\n",
    "        24 : 'cot_geospatial24',\n",
    "        25 : 'cot_geospatial25',\n",
    "        26 : 'cot_geospatial26',\n",
    "        27 : 'cot_geospatial27',\n",
    "        28 : 'cot_geospatial28'\n",
    "        }\n",
    "    func = switcher.get(mapserver_n)\n",
    "    return(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c82fe4d8-1d42-48ff-9134-b20cf0d059f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tablename(mapserver, layer_id, is_audited):\n",
    "    \"\"\"\n",
    "    Function to retrieve the name of the layer\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    mapserver\n",
    "        The mapserver that host the layer\n",
    "    layer_id\n",
    "        The id of the layer\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    output_name\n",
    "        The table name of the layer in database\n",
    "    \"\"\"\n",
    "    url = 'https://insideto-gis.toronto.ca/arcgis/rest/services/'+mapserver+'/MapServer/layers?f=json'\n",
    "    r = requests.get(url, verify = False)\n",
    "    ajson = r.json()\n",
    "    layers = ajson['layers']\n",
    "    for layer in layers:\n",
    "        if layer['id'] == layer_id:\n",
    "            output_name = (layer['name'].lower()).replace(' ', '_')\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # For the layers that will be pulled into a partitioned table, add the current pull's date to table name\n",
    "    if not is_audited:\n",
    "        today = datetime.date.today().strftime('_%Y%m%d')\n",
    "        output_name = output_name + today\n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621441e0-033c-4cde-8c69-94fc22b70c5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create table in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469f189b-0d9e-418d-9826-3ea795aa14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fieldtype(field):\n",
    "    if field == 'esriFieldTypeInteger' or field == 'esriFieldTypeSingle' or field == 'esriFieldTypeInteger' or field=='esriFieldTypeOID' or field == 'esriFieldTypeSmallInteger' or field =='esriFieldGlobalID':\n",
    "        fieldtype = 'integer'\n",
    "    elif field == 'esriFieldTypeString':\n",
    "        fieldtype = 'text'\n",
    "    elif field == 'esriFieldTypeDouble':\n",
    "        fieldtype = 'numeric'\n",
    "    elif field == 'esriFieldTypeDate':\n",
    "        fieldtype = 'timestamp without time zone'\n",
    "    return fieldtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30548ec-a710-4d85-9bf7-1a96f9c7b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_audited_table(output_table, return_json, schema_name, primary_key):\n",
    "    '''Create a new table in postgresql for the layer'''\n",
    "    \n",
    "    fields = return_json['fields']\n",
    "    insert_column_list = [sql.Identifier((field['name'].lower()).replace('.', '_')) for field in fields]\n",
    "    insert_column_list.append(sql.Identifier('geom'))\n",
    "    insert_column = sql.SQL(',').join(insert_column_list)\n",
    "    \n",
    "    # For audited tables only\n",
    "    excluded_column_list = [sql.SQL('EXCLUDED.') + sql.Identifier((field['name'].lower()).replace('.', '_')) for field in fields]\n",
    "    excluded_column_list.append(sql.Identifier('EXCLUDED.geom'))\n",
    "    excluded_column = sql.SQL(',').join(excluded_column_list)\n",
    "    \n",
    "    print(excluded_column.as_string(con))\n",
    "    \n",
    "    print('insert_column ' + insert_column.as_string(con))\n",
    "    \n",
    "    # Since this is a temporary table, name it '_table' as opposed to 'table' for now\n",
    "    temp_table_name = '_' + output_table\n",
    "    \n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            \n",
    "            col_list = [sql.Identifier((field['name'].lower()).replace('.', '_')) + sql.SQL(' ') + sql.SQL(get_fieldtype(field[\"type\"])) for field in fields]\n",
    "            col_list.append(sql.Identifier('geom') + sql.SQL(' ') + sql.SQL('geometry'))\n",
    "            col_list_string = sql.SQL(',').join(col_list)\n",
    "            \n",
    "            create_sql = sql.SQL(\"CREATE TABLE IF NOT EXISTS {schema}.{table} ({columns})\").format(schema = sql.Identifier(schema_name),\n",
    "                                                                      table = sql.Identifier(temp_table_name),\n",
    "                                                                      columns = col_list_string)\n",
    "            print('create_sql' + create_sql.as_string(con))\n",
    "            cur.execute(create_sql)\n",
    "    \n",
    "    # Add a pk\n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql.SQL(\"ALTER TABLE {schema}.{table} ADD PRIMARY KEY ({pk})\").format(schema = sql.Identifier(schema_name),\n",
    "                                                                                               table = sql.Identifier(temp_table_name),\n",
    "                                                                                               pk = sql.Identifier(primary_key)))\n",
    "    return insert_column, excluded_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c775a329-eeb4-4a3c-91a1-fce73d8835ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partitioned_table(output_table, return_json, schema_name):\n",
    "    fields = return_json['fields']\n",
    "    insert_column_list = [sql.Identifier((field['name'].lower()).replace('.', '_')) for field in fields]\n",
    "    insert_column_list.insert(0, sql.Identifier('version_date'))\n",
    "    insert_column_list.append(sql.Identifier('geom'))\n",
    "    insert_column = sql.SQL(',').join(insert_column_list)\n",
    "    \n",
    "    print(insert_column.as_string(con))\n",
    "    today_string = datetime.date.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Strip the date from output_table, and then add '_parent' to get the parent table name\n",
    "    parent_tablename = re.sub('_\\d+$', '', output_table) + '_parent'\n",
    "    \n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            \n",
    "            create_sql = sql.SQL(\"CREATE TABLE IF NOT EXISTS {child_table} PARTITION OF {schema}.{parent_table} FOR VALUES IN (%s)\").format(child_table = sql.Identifier(output_table),\n",
    "                                                                                                                                                     schema = sql.Identifier(schema_name),\n",
    "                                                                                                                                                     parent_table = sql.Identifier(parent_tablename),\n",
    "                                                                                                                                                     )\n",
    "            #create_sql = create_sql + sql.SQL('({})').format(today_string)\n",
    "            print('create_sql' + create_sql.as_string(con))\n",
    "            cur.execute(create_sql, (today_string, ))\n",
    "            #execute_values(cur, create_sql, (today_string, ))\n",
    "    \n",
    "    return insert_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeaa7d40-92c0-4a6e-8528-36f37ac26d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry Switcher \n",
    "def line(geom):\n",
    "    return 'SRID=4326;LineString('+','.join(' '.join(str(x) for x in tup) for tup in geom['paths'][0]) +')'\n",
    "def polygon(geom):\n",
    "    return 'SRID=4326;MultiPolygon((('+','.join(' '.join(str(x) for x in tup) for tup in geom['rings'][0]) +')))'\n",
    "def point(geom):\n",
    "    return 'SRID=4326;Point('+(str(geom['x']))+' '+ (str(geom['y']))+')'  \n",
    "def get_geometry(geometry_type, geom):\n",
    "    switcher = {\n",
    "        'esriGeometryLine':line,\n",
    "        'esriGeometryPolyline': line, \n",
    "        'esriGeometryPoint': point, \n",
    "        'esriGeometryMultiPolygon': polygon,\n",
    "        'esriGeometryPolygon': polygon\n",
    "    }\n",
    "    func = switcher.get(geometry_type)\n",
    "    geometry = (func(geom)) \n",
    "    return geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81928a3a-5710-4e06-a995-32db05be8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_time(input):\n",
    "    '''Convert epoch time to postgresql timestamp without time zone'''    \n",
    "    time = datetime.datetime.fromtimestamp(abs(input)/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131af05a-bace-4c10-81a7-bbf03d08bbf6",
   "metadata": {},
   "source": [
    "## Insert data from ArcGIS to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b12d17-fea1-422b-91e8-02f399cbdc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(mapserver, layer_id, max_number = None, record_max = None):\n",
    "    '''Get data from gcc view rest api'''        \n",
    "    base_url = \"https://insideto-gis.toronto.ca/arcgis/rest/services/{}/MapServer/{}/query\".format(mapserver, layer_id)\n",
    "    \n",
    "    \"\"\" Added stuff \"\"\"\n",
    "    \n",
    "    # If the data we want to get is centreline\n",
    "    if mapserver == 'cot_geospatial' and layer_id == 2:\n",
    "        query = {\"where\": \"\\\"FEATURE_CODE_DESC\\\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\",\n",
    "             \"outFields\": \"*\",\n",
    "             \"outSR\": '4326',         \n",
    "             \"returnGeometry\": \"true\",\n",
    "             \"returnTrueCurves\": \"false\",\n",
    "             \"returnIdsOnly\": \"false\",\n",
    "             \"returnCountOnly\": \"false\",\n",
    "             \"returnZ\": \"false\",\n",
    "             \"returnM\": \"false\",\n",
    "             \"orderByFields\": \"OBJECTID\", \n",
    "             \"returnDistinctValues\": \"false\",\n",
    "             \"returnExtentsOnly\": \"false\",\n",
    "             \"resultOffset\": \"{}\".format(max_number),\n",
    "             \"resultRecordCount\": \"{}\".format(record_max),\n",
    "             \"f\":\"json\"}\n",
    "        print(query[\"where\"])\n",
    "    else:\n",
    "        query = {\"where\":\"1=1\",\n",
    "             \"outFields\": \"*\",\n",
    "             \"outSR\": '4326',         \n",
    "             \"returnGeometry\": \"true\",\n",
    "             \"returnTrueCurves\": \"false\",\n",
    "             \"returnIdsOnly\": \"false\",\n",
    "             \"returnCountOnly\": \"false\",\n",
    "             \"returnZ\": \"false\",\n",
    "             \"returnM\": \"false\",\n",
    "             \"orderByFields\": \"OBJECTID\", \n",
    "             \"returnDistinctValues\": \"false\",\n",
    "             \"returnExtentsOnly\": \"false\",\n",
    "             \"resultOffset\": \"{}\".format(max_number),\n",
    "             \"resultRecordCount\": \"{}\".format(record_max),\n",
    "             \"f\":\"json\"}\n",
    "    \n",
    "    while True:\n",
    "        try :\n",
    "            r = requests.get(base_url, params = query, verify = False)\n",
    "        except requests.exceptions.ConnectionErrors:\n",
    "            sleep(10)\n",
    "            continue\n",
    "        else:\n",
    "            return_json = r.json() \n",
    "            break\n",
    "    return return_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e39cac-10a9-4d42-bbcd-53dda7643374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_limit(return_json):\n",
    "    '''Check if last query return all rows'''   \n",
    "    if return_json.get('exceededTransferLimit', False) == True:\n",
    "        keep_adding = True\n",
    "    else:\n",
    "        keep_adding = False\n",
    "    return keep_adding   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae775756-c82e-4320-b822-13001c4f5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_audited_data(output_table, insert_column, return_json, schema_name):\n",
    "    '''Send data to postgresql'''   \n",
    "    rows = []\n",
    "    features = return_json['features']\n",
    "    fields = return_json['fields']\n",
    "    trials = [[field['name'], field['type']] for field in fields]\n",
    "    for feature in features:\n",
    "        geom = feature['geometry']\n",
    "        geometry_type = return_json['geometryType']\n",
    "        geometry = get_geometry(geometry_type, geom)\n",
    "        row = [feature['attributes'][trial[0]] if trial[1] != 'esriFieldTypeDate' or feature['attributes'][trial[0]] == None else to_time(feature['attributes'][trial[0]]) for trial in trials]\n",
    "        row.append(geometry)\n",
    "        \n",
    "        rows.append(row)\n",
    "    \n",
    "    # Since this is a temporary table, name it '_table' as opposed to 'table' for now (for audited tables)\n",
    "    temp_table_name = '_' + output_table\n",
    "    \n",
    "    insert=sql.SQL(\"INSERT INTO {schema}.{table} ({columns}) VALUES %s\").format(\n",
    "        schema = sql.Identifier(schema_name), \n",
    "        table = sql.Identifier(temp_table_name), \n",
    "        columns = insert_column\n",
    "    )\n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "               execute_values(cur, insert, rows)\n",
    "    LOGGER.info('Successfully inserted %d records into %s', len(rows), output_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd05ccf3-892f-4e0b-9f5b-1d9f81c5177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_partitioned_data(output_table, insert_column, return_json, schema_name):\n",
    "    '''Send data to postgresql'''   \n",
    "    \n",
    "    today_string = datetime.date.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    rows = []\n",
    "    features = return_json['features']\n",
    "    fields = return_json['fields']\n",
    "    trials = [[field['name'], field['type']] for field in fields]\n",
    "    for feature in features:\n",
    "        geom = feature['geometry']\n",
    "        geometry_type = return_json['geometryType']\n",
    "        geometry = get_geometry(geometry_type, geom)\n",
    "        row = [feature['attributes'][trial[0]] if trial[1] != 'esriFieldTypeDate' or feature['attributes'][trial[0]] == None else to_time(feature['attributes'][trial[0]]) for trial in trials]\n",
    "        \n",
    "        row.insert(0, today_string)\n",
    "        row.append(geometry)\n",
    "        \n",
    "        rows.append(row)\n",
    "\n",
    "    \n",
    "    insert=sql.SQL(\"INSERT INTO {schema}.{table} ({columns}) VALUES %s\").format(\n",
    "        schema = sql.Identifier(schema_name), \n",
    "        table = sql.Identifier(output_table), \n",
    "        columns = insert_column\n",
    "    )\n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "               execute_values(cur, insert, rows)\n",
    "    LOGGER.info('Successfully inserted %d records into %s', len(rows), output_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241c229-ee15-4a89-840c-5f346e1a0dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enter mapserver_id and layer_id, get their PK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39e23a28-5854-4070-8191-e403b40cfbf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pk_dict = {\n",
    "\t\"city_ward\": \"area_id\",\n",
    "    \"census_tract\": \"area_id\",\n",
    "    \"neighbourhood_improvement_area\": \"area_id\",\n",
    "    \"priority_neighbourhood_for_investment\": \"area_id\",\n",
    "    \"ibms_district\": \"area_id\",\n",
    "    \"ibms_grid\": \"area_id\",\n",
    "    \"bikeway\": \"centreline_id\",\n",
    "    \"traffic_camera\": \"objectid\",\n",
    "    \"permit_parking_area\": \"objectid\",\n",
    "    \"prai_transit_shelter\": \"objectid\",\n",
    "    \"traffic_bylaw_point\": \"objectid\",\n",
    "    \"traffic_bylaw_line\": \"objectid\",\n",
    "    \"loop_detector\": \"objectid\",\n",
    "    \"electrical_vehicle_charging_station\": \"objectid\",\n",
    "    \"day_care_centre\": \"objectid\",\n",
    "    \"middle_childcare_centre\": \"objectid\",\n",
    "    \"business_improvement_area\": \"objectid\",\n",
    "    \"proposed_business_improvement_area\": \"objectid\",\n",
    "    \"film_permit_all\": \"objectid\",\n",
    "    \"film_permit_parking_all\": \"objectid\",\n",
    "    \"hotel\": \"objectid\",\n",
    "    \"convenience_store\": \"objectid\",\n",
    "    \"supermarket\": \"objectid\",\n",
    "    \"place_of_worship\": \"objectid\",\n",
    "    \"ymca\": \"objectid\",\n",
    "    \"aboriginal_organization\": \"objectid\",\n",
    "    \"attraction\": \"objectid\",\n",
    "    \"dropin\": \"objectid\",\n",
    "    \"early_years_centre\": \"objectid\",\n",
    "    \"family_resource_centre\": \"objectid\",\n",
    "    \"food_bank\": \"objectid\",\n",
    "    \"longterm_care\": \"objectid\",\n",
    "    \"parenting_family_literacy\": \"objectid\",\n",
    "    \"retirement_home\": \"objectid\",\n",
    "    \"senior_housing\": \"objectid\",\n",
    "    \"shelter\": \"objectid\",\n",
    "    \"social_housing\": \"objectid\",\n",
    "    \"private_road\": \"objectid\",\n",
    "    \"school\": \"objectid\",\n",
    "    \"library\": \"objectid\",\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d239476-9f45-4e0c-8672-08159731d601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concatenate_mapserver_layer(mapserver_n, layer_id):\n",
    "    num_pair = str(mapserver_n)+'_'+str(layer_id)\n",
    "    return num_pair\n",
    "\n",
    "# NEEDS TO BE UPDATED\n",
    "def retrieve_layer_name(num_pair):\n",
    "    switcher = {\n",
    "            '0_0': ward,\n",
    "            '0_2': centreline,\n",
    "            '2_2': bike,\n",
    "            '2_3': traffic_camera,\n",
    "            '2_9': traffic_signal,\n",
    "            '2_11': permit_parking,\n",
    "            '2_35': prai_transit_shelter, \n",
    "            '2_37': tmms_service_request,\n",
    "            '2_38': bylaw_pt,\n",
    "            '2_39': bylaw_line,\n",
    "            '20_1': ev_charging_station,\n",
    "            '22_1': day_care,\n",
    "            '22_2': middle_child,\n",
    "            '23_1': bia,\n",
    "            '23_13': proposed_bia,\n",
    "            '23_9': film_permit,\n",
    "            '23_10': film_parking,\n",
    "            '23_12': hotel,\n",
    "            '26_1': convenience_store,\n",
    "            '26_4': supermarket,\n",
    "            '26_3': worship,\n",
    "            '26_6': ymca,\n",
    "            '26_7': census_tract,\n",
    "            '26_11': neighbourhood_impro,\n",
    "            '26_13': priority_neigh,\n",
    "            '26_16': neigh_demo,\n",
    "            '26_45': aborginal,\n",
    "            '26_46': attraction,\n",
    "            '26_47': dropin, \n",
    "            '26_48': early_year,\n",
    "            '26_49': family_resource,\n",
    "            '26_50': food_bank,\n",
    "            '26_53': long_term_care,\n",
    "            '26_54': parenting_family_lit,\n",
    "            '26_58': retirement,\n",
    "            '26_59': senior_housing, \n",
    "            '26_61': shelter,\n",
    "            '26_62': social_housing,\n",
    "            '27_13': private_road,\n",
    "            '28_17': school,\n",
    "            '28_28': library\n",
    "    }\n",
    "    layer_name = switcher.get(num_pair)\n",
    "    return layer_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be34a19-228b-4272-86cf-43247a6580b3",
   "metadata": {},
   "source": [
    "## Update audited table (UPSERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8e1f5e-47ad-4e69-8945-6f70833c8a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_table(output_table, insert_column, primary_key):\n",
    "    \"\"\"Function to find differences between existing table and the newly created table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_table : string\n",
    "        Table name for postgresql, returned from function get_tablename\n",
    "\n",
    "    insert_column : string\n",
    "        String of column name and types use for creating a new postgresql table\n",
    "\n",
    "    primary_key : string\n",
    "        primary key for this layer, returned from function get_info\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Name the temporary table '_table' as opposed to 'table' for now\n",
    "    temp_table_name = '_' + output_table\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    date = (str(now.year)+str(now.month)+str(now.day))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    insert_column1 = str(insert_column).split(\",\")\n",
    "    \n",
    "    print(insert_column1)\n",
    "    \n",
    "    except_column = '('\n",
    "    for i in insert_column1:\n",
    "            except_value = \"EXCLUDED.{}\".format(i)\n",
    "            except_column = except_column + except_value +','        \n",
    "            \n",
    "    print('except_column: ' + except_column)\n",
    "    \n",
    "    excluded_column = except_column[:-1]+')'\n",
    "    print('excluded_column' + excluded_column)\n",
    "    \"\"\"\n",
    "    # Find if old table exists\n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(\"select count(1) from information_schema.tables where table_schema = 'gis' and table_name = '{}'\".format(output_table))\n",
    "            result = cur.fetchone()\n",
    "            # If table exists\n",
    "            if result[0] == 1:\n",
    "                # Delete rows that no longer exists in the new table\n",
    "                with con:\n",
    "                    with con.cursor() as cur:\n",
    "                        cur.execute(\"delete from gis.{} where {} = (select {} from gis.{} except select {} from gis._{})\".format(output_table, primary_key, primary_key, output_table, primary_key, output_table))\n",
    "\n",
    "                # And then upsert stuff\n",
    "                with con:\n",
    "                    with con.cursor() as cur:\n",
    "                        cur.execute(\"insert into gis.{} select {} from gis._{} on conflict({}) do update set {} = excluded.{} ; comment on table gis.{} is 'last updated: {}'\".format(output_table, insert_column, (insert_column[:-1])[1:], output_table, primary_key, insert_column,excluded_column,where_id, where_id, output_table, date)) \n",
    "                # And then drop the temp table\n",
    "                with con:\n",
    "                    with con.cursor() as cur:\n",
    "                         cur.execute(\"drop table if exists gis._{}\".format(output_table))\n",
    "                LOGGER.info('Updated table %s', output_table)           \n",
    "            # if table does not exist -> create a new one and add to audit list\n",
    "            else: \n",
    "                with con:\n",
    "                    with con.cursor() as cur:\n",
    "                        cur.execute(\"alter table gis._{} rename to {}; comment on table gis.{} is 'last updated: {}'\".format(output_table, output_table,output_table, date))\n",
    "                with con:\n",
    "                    with con.cursor() as cur:\n",
    "                        cur.execute(\"select gis.audit_table('gis.{}')\".format(output_table))\n",
    "                        LOGGER.info('New table %s created and added to audit table list', output_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5334fbd3-241c-4630-a707-6c0314a99f2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main function that the Task calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5146472b-1a30-4599-b510-5900ba22fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added 'schema_name' to the function\n",
    "def get_layer(mapserver_n, layer_id, schema_name, is_audited):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function calls to the GCCview rest API and inserts the outputs to the output table in the postgres database.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapserver : int\n",
    "        The name of the mapserver that host the desire layer\n",
    "\n",
    "    layer_id : int\n",
    "        The id of desire layer\n",
    "        \n",
    "    \"\"\"  \n",
    "    mapserver = mapserver_name(mapserver_n)\n",
    "    output_table = get_tablename(mapserver, layer_id, is_audited)\n",
    "    #--------------------------------\n",
    "    if is_audited:\n",
    "        primary_key = pk_dict.get(output_table)\n",
    "    #--------------------------------\n",
    "    keep_adding = True\n",
    "    counter = 0\n",
    "    \n",
    "    while keep_adding == True:\n",
    "        \n",
    "        if counter == 0:\n",
    "            return_json = get_data(mapserver, layer_id)\n",
    "            if is_audited:\n",
    "                (insert_column, excluded_column) = create_audited_table(output_table, return_json, schema_name, primary_key)\n",
    "            else:\n",
    "                insert_column = create_partitioned_table(output_table, return_json, schema_name)\n",
    "            features = return_json['features']\n",
    "            record_max=(len(features))\n",
    "            max_number = record_max\n",
    "            # Added 'schema_name'\n",
    "            if is_audited:\n",
    "                insert_audited_data(output_table, insert_column, return_json, schema_name)\n",
    "            else:\n",
    "                insert_partitioned_data(output_table, insert_column, return_json, schema_name)\n",
    "            #insert_data(output_table, insert_column, return_json, schema_name, is_audited)\n",
    "            counter += 1\n",
    "            keep_adding = find_limit(return_json)\n",
    "            if keep_adding == False:\n",
    "                LOGGER.info('All records from [mapserver: %s, layerID: %d] have been inserted into %s', mapserver, layer_id, output_table)\n",
    "        else:\n",
    "            return_json = get_data(mapserver, layer_id, max_number = max_number, record_max = record_max)\n",
    "            if is_audited:\n",
    "                insert_audited_data(output_table, insert_column, return_json, schema_name)\n",
    "            else:\n",
    "                insert_partitioned_data(output_table, insert_column, return_json, schema_name)\n",
    "            #insert_data(output_table, insert_column, return_json, schema_name, is_audited)\n",
    "            counter += 1\n",
    "            keep_adding = find_limit(return_json)\n",
    "            if keep_adding == True:\n",
    "                max_number = max_number + record_max\n",
    "            else:\n",
    "                LOGGER.info('All records from [mapserver: %s, layerID: %d] have been inserted into %s', mapserver, layer_id, output_table)\n",
    "    \n",
    "    #if is_audited:\n",
    "        #update_table(output_table, insert_column, primary_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544566c-997d-4057-b3fa-eca2d2dd35ef",
   "metadata": {},
   "source": [
    "## Testing out input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a609f9f7-9fa0-467f-8adf-70dbf427781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapserver_n = 0\n",
    "layer_id = 2\n",
    "schema_name = 'bqu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2729588-fc01-4aea-b619-3ee92654e38d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n",
      "\"version_date\",\"centreline_id\",\"linear_name_id\",\"linear_name_full\",\"linear_name_full_legal\",\"address_l\",\"address_r\",\"parity_l\",\"parity_r\",\"lo_num_l\",\"hi_num_l\",\"lo_num_r\",\"hi_num_r\",\"begin_addr_point_id_l\",\"end_addr_point_id_l\",\"begin_addr_point_id_r\",\"end_addr_point_id_r\",\"begin_addr_l\",\"end_addr_l\",\"begin_addr_r\",\"end_addr_r\",\"linear_name\",\"linear_name_type\",\"linear_name_dir\",\"linear_name_desc\",\"linear_name_label\",\"from_intersection_id\",\"to_intersection_id\",\"oneway_dir_code\",\"oneway_dir_code_desc\",\"feature_code\",\"feature_code_desc\",\"jurisdiction\",\"centreline_status\",\"shape_length\",\"objectid\",\"shape_len\",\"mi_prinx\",\"low_num_odd\",\"high_num_odd\",\"low_num_even\",\"high_num_even\",\"geom\"\n",
      "create_sqlCREATE TABLE IF NOT EXISTS \"centreline_20220928\" PARTITION OF \"bqu\".\"centreline_parent\" FOR VALUES IN (%s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 1000 records into centreline_20220928\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"FEATURE_CODE_DESC\" IN ('Collector','Collector Ramp','Expressway','Expressway Ramp','Local','Major Arterial','Major Arterial Ramp','Minor Arterial','Minor Arterial Ramp','Pending')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapserver_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_audited\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36mget_layer\u001b[0;34m(mapserver_n, layer_id, schema_name, is_audited)\u001b[0m\n\u001b[1;32m     49\u001b[0m     insert_audited_data(output_table, insert_column, return_json, schema_name)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[43minsert_partitioned_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsert_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#insert_data(output_table, insert_column, return_json, schema_name, is_audited)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36minsert_partitioned_data\u001b[0;34m(output_table, insert_column, return_json, schema_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m con:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m con\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[0;32m---> 29\u001b[0m            \u001b[43mexecute_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuccessfully inserted \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m records into \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(rows), output_table)\n",
      "File \u001b[0;32m/opt/jupyterhub/lib64/python3.9/site-packages/psycopg2/extras.py:1270\u001b[0m, in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1269\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[0;32m-> 1270\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n\u001b[1;32m   1272\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(cur\u001b[38;5;241m.\u001b[39mfetchall())\n",
      "File \u001b[0;32m/usr/lib64/python3.9/encodings/utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[1;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_layer(mapserver_n, layer_id, schema_name, is_audited = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69913ab0-1a7c-4ac5-a1c2-bc98f282642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapserver_n = 0\n",
    "layer_id = 0\n",
    "schema_name = 'bqu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a098763-aad6-49d1-90ac-9eca242e8a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/jupyterhub/lib64/python3.9/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'insideto-gis.toronto.ca'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXCLUDED.\"area_id\",EXCLUDED.\"date_effective\",EXCLUDED.\"date_expiry\",EXCLUDED.\"area_attr_id\",EXCLUDED.\"area_type_id\",EXCLUDED.\"parent_area_id\",EXCLUDED.\"area_type\",EXCLUDED.\"area_class_id\",EXCLUDED.\"area_class\",EXCLUDED.\"area_short_code\",EXCLUDED.\"area_long_code\",EXCLUDED.\"area_name\",EXCLUDED.\"area_desc\",EXCLUDED.\"feature_code\",EXCLUDED.\"feature_code_desc\",EXCLUDED.\"trans_id_create\",EXCLUDED.\"trans_id_expire\",EXCLUDED.\"x\",EXCLUDED.\"y\",EXCLUDED.\"longitude\",EXCLUDED.\"latitude\",EXCLUDED.\"objectid\",EXCLUDED.\"shape_area\",EXCLUDED.\"shape_len\",\"EXCLUDED.geom\"\n",
      "insert_column \"area_id\",\"date_effective\",\"date_expiry\",\"area_attr_id\",\"area_type_id\",\"parent_area_id\",\"area_type\",\"area_class_id\",\"area_class\",\"area_short_code\",\"area_long_code\",\"area_name\",\"area_desc\",\"feature_code\",\"feature_code_desc\",\"trans_id_create\",\"trans_id_expire\",\"x\",\"y\",\"longitude\",\"latitude\",\"objectid\",\"shape_area\",\"shape_len\",\"geom\"\n",
      "create_sqlCREATE TABLE IF NOT EXISTS \"bqu\".\"_city_ward\" (\"area_id\" numeric,\"date_effective\" timestamp without time zone,\"date_expiry\" timestamp without time zone,\"area_attr_id\" numeric,\"area_type_id\" numeric,\"parent_area_id\" numeric,\"area_type\" text,\"area_class_id\" numeric,\"area_class\" text,\"area_short_code\" text,\"area_long_code\" text,\"area_name\" text,\"area_desc\" text,\"feature_code\" integer,\"feature_code_desc\" text,\"trans_id_create\" numeric,\"trans_id_expire\" numeric,\"x\" numeric,\"y\" numeric,\"longitude\" numeric,\"latitude\" numeric,\"objectid\" integer,\"shape_area\" numeric,\"shape_len\" numeric,\"geom\" geometry)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully inserted 25 records into city_ward\n",
      "INFO:__main__:All records from [mapserver: cot_geospatial, layerID: 0] have been inserted into city_ward\n"
     ]
    }
   ],
   "source": [
    "get_layer(mapserver_n, layer_id, schema_name, is_audited = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458bffa-3c07-47e9-bf95-a7ec9c206f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
